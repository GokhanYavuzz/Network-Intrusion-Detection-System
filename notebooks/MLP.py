import os
import pandas as pd
import numpy as np
import time
from sklearn.calibration import LabelEncoder
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn # PyTorch neural network modÃ¼lÃ¼
import torch.optim as optim # PyTorch optimizers
from torch.utils.data import DataLoader, TensorDataset # Veri yÃ¼kleyici ve dataset
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns

# ==========================================
# 2. VERÄ° YÃœKLEME VE HAZIRLIK
# ==========================================

print("Dosya okunuyor...")
df = pd.read_csv('C:\\Users\\GÃ¶khan\\Desktop\\GÃ¶khan\\nids-adversarial\\data\\with_attack_cat_clear_data.csv', low_memory=False)

df['attack_cat'] = df['attack_cat'].str.strip() # BoÅŸluklarÄ± temizle

# ==========================================
# 2. FÄ°LTRELEME (SADECE NORMAL VE FUZZERS)
# ==========================================
print("Veri seti filtreleniyor (Sadece Normal ve Fuzzers)...")

# SaldÄ±rÄ± tÃ¼rÃ¼ sÃ¼tununun adÄ±nÄ± kontrol et (Genelde 'attack_cat')
attack_col = 'attack_cat' 

# Sadece 'Normal' veya 'Fuzzers' iÃ§eren satÄ±rlarÄ± seÃ§
# (str.contains kullanarak boÅŸluk veya bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf hatalarÄ±nÄ± Ã¶nlÃ¼yoruz)
df_filtered = df[df[attack_col].astype(str).str.contains("Normal|Fuzzer", case=False, regex=True)].copy()

print(f"Orijinal Veri SayÄ±sÄ±: {len(df)}")
print(f"FiltrelenmiÅŸ Veri SayÄ±sÄ±: {len(df_filtered)}")
print("Kalan SÄ±nÄ±flar:", df_filtered[attack_col].unique())

# ==========================================
# 3. ETÄ°KETLEME (LABEL ENCODING)
# ==========================================
# Normal -> 0
# Fuzzers -> 1 yapmamÄ±z lazÄ±m.

# Ã–nce mevcut 'label' sÃ¼tununu (varsa) dÃ¼ÅŸÃ¼relim, biz kendimiz en doÄŸrusunu oluÅŸturacaÄŸÄ±z.
if 'label' in df_filtered.columns:
    df_filtered = df_filtered.drop(columns=['label'])

# Yeni label oluÅŸturma: Normal ise 0, deÄŸilse (Fuzzer) 1
df_filtered['label'] = df_filtered[attack_col].apply(lambda x: 0 if 'Normal' in str(x) else 1)

print("\nEtiketler gÃ¼ncellendi: Normal=0, Fuzzer=1")
print(df_filtered[[attack_col, 'label']].value_counts())

# ==========================================
# 4. X ve y AYRIMI
# ==========================================
# Etiket sÃ¼tunlarÄ±nÄ± X'ten Ã§Ä±kar
y = df_filtered[[attack_col, 'label']] # Hem ismini hem 0/1 halini saklayalÄ±m
X = df_filtered.drop(columns=[attack_col, 'label'])

print("Kategorik (yazÄ±) sÃ¼tunlar sayÄ±ya Ã§evriliyor...")
# Nesne (object) tipindeki yani yazÄ± olan sÃ¼tunlarÄ± bul
cat_cols = X.select_dtypes(include=['object']).columns

if len(cat_cols) > 0:
    print(f"DÃ¶nÃ¼ÅŸtÃ¼rÃ¼len sÃ¼tunlar: {list(cat_cols)}")
    for col in cat_cols:
        le = LabelEncoder()
        # SÃ¼tunu string'e Ã§evirip encode ediyoruz (hatayÄ± Ã¶nlemek iÃ§in)
        X[col] = le.fit_transform(X[col].astype(str))
else:
    print("DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecek metin sÃ¼tunu bulunamadÄ± (Zaten hepsi sayÄ±).")

# ==========================================
# 5. EÄžÄ°TÄ°M / TEST BÃ–LME (%80 - %20)
# ==========================================
print("\nVeri bÃ¶lÃ¼nÃ¼yor (%80 Train - %20 Test)...")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.20, 
    random_state=42, 
    stratify=y['label'] # Normal/Fuzzer oranÄ± bozulmasÄ±n diye
)

# ==========================================
# 6. KAYDETME
# ==========================================
print("Dosyalar kaydediliyor...")

X_train.to_csv(os.path.join('C:\\Users\\GÃ¶khan\\Desktop\\GÃ¶khan\\nids-adversarial\\data\\mlp_data', "X_train_fuzzer.csv"), index=False)
X_test.to_csv(os.path.join('C:\\Users\\GÃ¶khan\\Desktop\\GÃ¶khan\\nids-adversarial\\data\\mlp_data', "X_test_fuzzer.csv"), index=False)
y_train.to_csv(os.path.join('C:\\Users\\GÃ¶khan\\Desktop\\GÃ¶khan\\nids-adversarial\\data\\mlp_data', "y_train_fuzzer.csv"), index=False)
y_test.to_csv(os.path.join('C:\\Users\\GÃ¶khan\\Desktop\\GÃ¶khan\\nids-adversarial\\data\\mlp_data', "y_test_fuzzer.csv"), index=False)

print("\nÄ°ÅžLEM TAMAM! ðŸš€")
print("ArtÄ±k klasÃ¶rÃ¼nde sadece Normal ve Fuzzers iÃ§eren temiz X_train, y_train dosyalarÄ±n var.")

# ==========================================
# 1. AYARLAR VE CÄ°HAZ SEÃ‡Ä°MÄ°
# ==========================================
# GPU varsa kullan, yoksa CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"KullanÄ±lan cihaz: {device}")

# Hiperparametreler (Orijinal notebook ile uyumlu)
BATCH_SIZE = 64 
LEARNING_RATE = 1e-3 
EPOCHS = 50 
L2_REGULARIZATION = 1e-4  # Sklearn'deki 'alpha' parametresi PyTorch'ta weight_decay'dir

print("Veriler yÃ¼kleniyor...")
# Dosya yollarÄ±nÄ± kendi sisteminize gÃ¶re gÃ¼ncelleyebilirsiniz

# Orijinal notebooktaki yollar
X_train = pd.read_csv(r"C:\Users\GÃ¶khan\Desktop\GÃ¶khan\nids-adversarial\data\mlp_data\X_train_fuzzer.csv", low_memory=False)
y_train = pd.read_csv(r"C:\Users\GÃ¶khan\Desktop\GÃ¶khan\nids-adversarial\data\mlp_data\y_train_fuzzer.csv", low_memory=False)
X_test = pd.read_csv(r"C:\Users\GÃ¶khan\Desktop\GÃ¶khan\nids-adversarial\data\mlp_data\X_test_fuzzer.csv", low_memory=False)
y_test = pd.read_csv(r"C:\Users\GÃ¶khan\Desktop\GÃ¶khan\nids-adversarial\data\mlp_data\y_test_fuzzer.csv", low_memory=False)

# ==========================================
# 3. VERÄ° Ã–N Ä°ÅžLEME (StandardScaler & Tensor DÃ¶nÃ¼ÅŸÃ¼mÃ¼)
# ==========================================
print("Veriler Ã¶lÃ§eklendiriliyor ve Tensor'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")

# Ã–zellikleri Ã¶lÃ§ekleme (StandardScaler)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train) # EÄŸitim verisini standartlaÅŸtÄ±r
X_test_scaled = scaler.transform(X_test) # Test verisini aynÄ± scaler ile dÃ¶nÃ¼ÅŸtÃ¼r

# Numpy array'leri PyTorch Tensor'larÄ±na Ã§evirme
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device) # Veriyi Tensor'a Ã§evir ve ondalÄ±klÄ± yapÄ±ya Ã§evir
y_train_tensor = torch.tensor(y_train['label'].values, dtype=torch.float32).unsqueeze(1).to(device) # y_train iÃ§inden sadece 'label' sÃ¼tununu al

X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device) # Test verisini Tensor'a Ã§evir 
y_test_tensor = torch.tensor(y_test['label'].values, dtype=torch.float32).unsqueeze(1).to(device) # y_test iÃ§inden sadece 'label' sÃ¼tununu al

# DataLoader oluÅŸturma (Batch iÅŸlemleri iÃ§in)
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) # Veri karÄ±ÅŸtÄ±rma ve batch'leme. Ram kullanÄ±mÄ± iÃ§in.

# ==========================================
# 4. MODEL MÄ°MARÄ°SÄ° (PyTorch)
# ==========================================
class SurrogateMLP(nn.Module):
    def __init__(self, input_dim):
        super(SurrogateMLP, self).__init__()
        # Sklearn: hidden_layer_sizes=(128, 64)
        self.layer1 = nn.Linear(input_dim, 128)
        self.relu1 = nn.ReLU()                                                  #BURADA NEDEN 2 TANE LAYER VAR DAHA FAZLA OLMALI DEÄžÄ°L MÄ°?
        self.layer2 = nn.Linear(128, 64)
        self.relu2 = nn.ReLU()
        self.output = nn.Linear(64, 1) # Binary classification iÃ§in tek Ã§Ä±ktÄ±
        self.sigmoid = nn.Sigmoid()    # OlasÄ±lÄ±k deÄŸeri (0-1 arasÄ±)

    def forward(self, x):
        x = self.relu1(self.layer1(x))
        x = self.relu2(self.layer2(x))
        x = self.sigmoid(self.output(x))
        return x
if __name__ == "__main__":
    print("MLP.py doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±, eÄŸitim baÅŸlÄ±yor...")

    input_dim = X_train.shape[1]
    model = SurrogateMLP(input_dim).to(device)
    print(f"Model oluÅŸturuldu: {model}")

    # Loss ve Optimizer
    criterion = nn.BCELoss() # Hata yapmasÄ± durumunda ceza gÃ¶nderen Binary Cross Entropy Loss
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=L2_REGULARIZATION) # Adam optimizasyon algoritmasÄ±, hatayÄ± minimize eder

    # ==========================================
    # 5. EÄžÄ°TÄ°M DÃ–NGÃœSÃœ
    # ==========================================
    print("EÄŸitim baÅŸlÄ±yor...")
    loss_history = []

    start_time = time.time() # Kronometreyi baÅŸlat (Toplam sÃ¼re iÃ§in)
    epoch_start_time = time.time() # Her 5'lik blok iÃ§in ara zamanlayÄ±cÄ±

    model.train()
    for epoch in range(EPOCHS):
        epoch_loss = 0
        for X_batch, y_batch in train_loader:
            # 1. Gradiyentleri sÄ±fÄ±rla
            optimizer.zero_grad()
        
            # 2. Ä°leri besleme (Forward pass)
            predictions = model(X_batch)
        
            # 3. Hata hesaplama
            loss = criterion(predictions, y_batch.view(-1, 1))
        
            # 4. Geri yayÄ±lÄ±m (Backpropagation)
            loss.backward()
        
            # 5. AÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle
            optimizer.step()

            epoch_loss += loss.item()

        avg_loss = epoch_loss / len(train_loader)
        loss_history.append(avg_loss)
    
        if (epoch + 1) % 5 == 0:
            current_time = time.time()
            batch_time = current_time - epoch_start_time # Son 5 epoch ne kadar sÃ¼rdÃ¼?
            total_time = current_time - start_time       # BaÅŸlangÄ±Ã§tan beri ne kadar geÃ§ti?
        
            print(f"Epoch [{epoch+1}/{EPOCHS}] | "
                  f"Loss: {avg_loss:.4f} | "
                  f"Son 5 Epoch SÃ¼resi: {batch_time:.2f} sn | "
                  f"Toplam SÃ¼re: {total_time:.2f} sn")
        
            # Ara zamanlayÄ±cÄ±yÄ± sÄ±fÄ±rla
            epoch_start_time = current_time

    # KayÄ±p grafiÄŸini Ã§izme (Ä°steÄŸe baÄŸlÄ±)
    plt.figure(figsize=(10,5))
    plt.plot(loss_history, label='Training Loss')
    plt.title('EÄŸitim SÃ¼recinde KayÄ±p (Loss)')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()
    # ==========================================
    # 6. DEÄžERLENDÄ°RME
    # ==========================================
    print("Test seti Ã¼zerinde deÄŸerlendirme yapÄ±lÄ±yor...")
    model.eval() # DeÄŸerlendirme modu (Dropout vs. kapatÄ±r)

    with torch.no_grad():
        y_pred_prob = model(X_test_tensor)
        # OlasÄ±lÄ±klarÄ± 0 veya 1'e yuvarla (Threshold 0.5)
        y_pred = (y_pred_prob > 0.5).float().cpu().numpy()
        y_test_np = y_test_tensor.cpu().numpy()
    # Raporlama
    print("\nClassification Report:")
    print(classification_report(y_test_np.flatten(), y_pred.flatten(), digits=4))

    # Confusion Matrix
    cm = confusion_matrix(y_test_np.flatten(), y_pred.flatten())
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix (PyTorch MLP)')
    plt.show()

    # ==========================================
    # 7. MODELÄ° KAYDETME (Ä°steÄŸe baÄŸlÄ±)
    # ==========================================
    # GAN eÄŸitimi sÄ±rasÄ±nda tekrar yÃ¼klemek iÃ§in:
    torch.save(model.state_dict(), "surrogate_mlp_model.pth")
    print("Model 'surrogate_mlp_model.pth' olarak kaydedildi.")